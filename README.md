# AI-Bootcamp-FYP
This project implements a question-answering system using the Mistral-7B-Instruct-v0.2 model.
Question Answering System with Mistral-7B-Instruct-v0.2

# Project Overview
This project implements a question-answering system using the Mistral-7B-Instruct-v0.2 model, which provides accurate and contextually relevant responses to user queries. The model has been integrated into a web application with Gradio serving as the frontend and FastAPI managing the backend processes. Users can input their questions through the Gradio interface, which communicates with the FastAPI server to retrieve answers generated by the Mistral-7B model. This setup demonstrates how advanced language models can be utilized in practical applications for real-time interaction and information retrieval

# Features
Interactive Q&A: Users can interact with the Mistral-7B model by asking questions and receiving precise answers.

Gradio Interface: A simple and intuitive web-based interface that allows users to input questions and view answers in real-time.

FastAPI Backend: A fast and efficient backend server that handles requests from the Gradio interface and communicates with the Mistral-7B model to generate responses.

Deployed on Hugging Face: The model is also deployed on Hugging Face Spaces for easy access and interaction.

# Technology Stack
Mistral-7B-Instruct-v0.2 Model: A powerful language model used for generating contextually relevant answers to questions.

Gradio: A Python library that provides an easy-to-use web interface, allowing users to interact with the model directly from their browser.

FastAPI: A modern, fast (high-performance), web framework for building APIs with Python, which serves as the backend of the application to handle requests and manage the interaction between the Gradio interface and the Mistral-7B model.

ngrok: Used for creating secure tunnels to localhost, making the FastAPI server accessible over the internet.

# Installation
1. Install the required dependencies
2. Run the Application

# Usage
Online Deployment: Visit the Hugging Face Space where the model is deployed here.

# Deployment on Hugging Face
The project is also deployed on Hugging Face Spaces, allowing users to interact with the model directly online. Visit the deployed project here [https://huggingface.co/spaces/kzahra/QnA_FYP].

# Output
## Output 1
![Output](https://github.com/user-attachments/assets/5d448df7-ec20-4f89-bd1e-65adfa693f4b)

## Output 2
![output 1](https://github.com/user-attachments/assets/8ca48997-db8c-4a9c-a7c2-dbd213d3f56f)

